{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0aba4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3056c277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91954\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91954\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open('chatbot.txt','r',errors='ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "sent=nltk.sent_tokenize(raw)\n",
    "word=nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44309cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data,[1][2] and apply knowledge from data across a broad range of application domains.',\n",
       " 'data science is related to data mining, machine learning and big data.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03f235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'science']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6adec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer=nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return[lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict=dict((ord(punct),None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdcaef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREET_INPUT=(\"hello\",\"hi\",\"hey\",\"sup\",\"what's up\",\"namaste\")\n",
    "GREET_RESPONSES=[\"hi\",\"hey\",\"hi there\",\"hello\",\"i am glad! you are talking to me\"]\n",
    "\n",
    "def greet(sentence):\n",
    "    for words in sentence.split():\n",
    "        if words.lower() in GREET_INPUT:\n",
    "            return random.choice(GREET_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f66b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7695dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_res):\n",
    "    robo_res=' '\n",
    "    TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "    tfidf=TfidfVec.fit_transform(sent)\n",
    "    vals=cosine_similarity(tfidf[-1],tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat=vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf=flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_res=robo_res+\"I am sorry! I don't understand you\"\n",
    "        return robo_res\n",
    "    else:\n",
    "        robo_res=robo_res+sent[idx]\n",
    "        return robo_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b931c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT:My name is stark. Let's have a conversation! Also, if you want to exit any time. just type bye!\n",
      "hi\n",
      "BOT:hi\n",
      "foundations\n",
      "BOT:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91954\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [7]\n",
      "\n",
      "\n",
      "contents\n",
      "1\tfoundations\n",
      "1.1\trelationship to statistics\n",
      "2\tetymology\n",
      "2.1\tearly usage\n",
      "2.2\tmodern usage\n",
      "3\tsee also\n",
      "4\treferences\n",
      "foundations\n",
      "data science is an interdisciplinary field focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains.\n",
      "data science\n",
      "BOT:   \"about data science\".\n",
      "techniques\n",
      "BOT:   [14] others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data.\n",
      "technologies and techniques\n",
      "BOT:   [14] others argue that data science is distinct from statistics because it focuses on problems and techniques unique to digital data.\n",
      "references\n",
      "BOT:   [31]\n",
      "\n",
      "see also\n",
      "international journal of population data science\n",
      "references\n",
      " dhar, v. (2013).\n",
      "thank you\n",
      "BOT:You are welcome ..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"BOT:My name is stark. Let's have a conversation! Also, if you want to exit any time. just type bye!\")\n",
    "while(flag==True):\n",
    "    user_res=input()\n",
    "    user_res=user_res.lower()\n",
    "    if(user_res!='bye'):\n",
    "        if(user_res=='thanks 'or user_res=='thank you'):\n",
    "            flag=False\n",
    "            print(\"BOT:You are welcome ..\")\n",
    "        else:\n",
    "            if(greet(user_res)!=None):\n",
    "                print(\"BOT:\"+greet(user_res))\n",
    "            else:\n",
    "                sent.append(user_res)\n",
    "                word=word+nltk.word_tokenize(user_res)\n",
    "                final_word=list(set(word))\n",
    "                print(\"BOT: \",end=\" \")\n",
    "                print(response(user_res))\n",
    "                sent.remove(user_res)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"BOT: Goobye! Take Care <3 <3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
